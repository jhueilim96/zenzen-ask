{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General API call flow\n",
    "\n",
    "#### Steps\n",
    "\n",
    "1. Producer = Prepare API request\n",
    "   1. Get template from folder\n",
    "   2. Get ANIME seed from seed folder\n",
    "   3. One media per producer task\n",
    "      1. Producer loop through page\n",
    "      2. Wait result to arive\n",
    "      3. check `hasNextPage=True`\n",
    "      4. Repeat\n",
    "   4. Render variables\n",
    "      1. perPage = 25 (max allowed)\n",
    "      2. `current_page` parameteriz\n",
    "   5. Manager\n",
    "      1. Singleton implementation\n",
    "      2. class attribute `api_call_count` to keep track all running jobs & get updated by header `X-RATE-LIMIT-REMAINING-API`\n",
    "      3. Decide to start new producer task\n",
    "      4. Require timer of 60 seconds to know duration of waiting when limit is hit\n",
    "2. Consumer = Response parser and storage\n",
    "   1. Parse `data` key\n",
    "   2. Set storage destinationjson -> 1 json per api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import aiohttp\n",
    "from queue import Queue\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import duckdb \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def make_api_call(url, query, variables):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(url, json={'query': query, 'variables': variables}) as resp:\n",
    "            result = await resp.json()\n",
    "            header = resp.headers\n",
    "            status_code = resp.status\n",
    "            return result, resp\n",
    "        \n",
    "async def producer(queue, ids:list[int], url, query, max_per_page):\n",
    "    print(\"Producer: Started\")\n",
    "    remaining_request = 90\n",
    "\n",
    "    for id in ids:\n",
    "\n",
    "        has_next_page = True\n",
    "        current_page = 0\n",
    "\n",
    "        while has_next_page:\n",
    "\n",
    "            variables = {  \n",
    "                'page': current_page,\n",
    "                'perPage': max_per_page,\n",
    "                'media_id': id\n",
    "            }\n",
    "\n",
    "            if remaining_request < 10:\n",
    "                print(\"Pause to recover limit\")\n",
    "                await asyncio.sleep(30)\n",
    "\n",
    "            print(f\"Requesting page {current_page} for {id}\")\n",
    "            result, resp = await make_api_call(url, query, variables)            \n",
    "            header = resp.headers\n",
    "\n",
    "            if resp.status != 200:\n",
    "                print(f\"Request fails at {id}\")\n",
    "                raise resp.raise_for_status()\n",
    "\n",
    "            await queue.put((result, id, current_page))\n",
    "            remaining_request = int(header.get('x-ratelimit-remaining'))\n",
    "            print(f'Remaining API call per min: {remaining_request}')\n",
    "\n",
    "            has_next_page = result.get('data').get('Media').get('characters').get('pageInfo').get('hasNextPage')\n",
    "            \n",
    "            if has_next_page:\n",
    "                current_page += 1\n",
    "            else:\n",
    "                print(f'{id} has completed all pagination')\n",
    "                break\n",
    "\n",
    "    print('Producer: Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def save_api_to_local(file_path:str, data: dict):\n",
    "    with open(file_path, 'w') as fp:\n",
    "        json.dump(data, fp)\n",
    "\n",
    "async def consumer(queue:asyncio.Queue, storage_path:Path):\n",
    "    print(\"Consumer: Started\")\n",
    "    while True:\n",
    "\n",
    "        response_body, id, current_page = await queue.get()\n",
    "        filename = Path(f'{id}-{current_page}.json')\n",
    "        file_path = storage_path / filename\n",
    "        print(f'Saving {id} at {file_path.as_posix()}')\n",
    "        await save_api_to_local(file_path=str(file_path), data=response_body)\n",
    "        queue.task_done()\n",
    "        print(f'Saving {id} completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Initialization\n",
    "MAX_PER_PAGE = 25\n",
    "MAX_API_PER_MIN = 90\n",
    "SEED_BATCH_SIZE = 50\n",
    "\n",
    "url = 'https://graphql.anilist.co'\n",
    "\n",
    "# Storage \n",
    "base_path = Path().cwd().parent\n",
    "storage_path = base_path / Path('raw/entity/anime-character')\n",
    "seed_path = base_path / Path('raw/seed/top-anime.csv')\n",
    "\n",
    "seeds = duckdb.read_csv(str(seed_path))\n",
    "total_rows = seeds.shape[0]\n",
    "\n",
    "template_path = Path(r'graphql-template\\get-anime-character.graphql')\n",
    "with open(str(template_path), 'r') as fp:\n",
    "    template = fp.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batches in range(500, seeds.shape[0], SEED_BATCH_SIZE):\n",
    "\n",
    "    seeds_batch = duckdb.sql(f\"\"\"\n",
    "        SELECT media_id \n",
    "        FROM seeds\n",
    "        LIMIT {SEED_BATCH_SIZE}\n",
    "        OFFSET {batches}\n",
    "    \"\"\").fetchall()\n",
    "    ids = [_[0] for _ in seeds_batch]\n",
    "\n",
    "    print(f\"Batch: {batches}\")\n",
    "\n",
    "    queue = asyncio.Queue(SEED_BATCH_SIZE)\n",
    "    # start the consumer\n",
    "    _ = asyncio.create_task(consumer(queue, storage_path))\n",
    "    # start the producer and wait for it to finish\n",
    "    await asyncio.create_task(producer(queue, ids, url, template, MAX_PER_PAGE))\n",
    "    # wait for all items to be processed\n",
    "    await queue.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [filename.name.split('-')[0] for filename in storage_path.glob('*.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filenames))\n",
    "print(len(set(filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
