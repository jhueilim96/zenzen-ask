{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General API call flow\n",
    "\n",
    "#### Steps\n",
    "\n",
    "1. Producer = Prepare API request\n",
    "   1. Get template from folder\n",
    "   2. Render variables\n",
    "      1. perPage = 10 (for traffic handling purpose)\n",
    "   3. Check limit before proceed\n",
    "      1. Use time aware queing\n",
    "2. Consumer = Response parser and storage\n",
    "   1. Parse `data` key\n",
    "   2. Set storage destinationjson -> 1 json per api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def make_api_call(url, query, variables):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(url, json={'query': query, 'variables': variables}) as resp:\n",
    "            result = await resp.json()\n",
    "            header = resp.headers\n",
    "            return result, header\n",
    "        \n",
    "async def producer_work(queue, current_page, url, query, per_page):\n",
    "\n",
    "    variables = {  \n",
    "        'page': current_page,\n",
    "        'perPage': per_page\n",
    "    }\n",
    "    print(f\"Requesting page {current_page} at {url}\")\n",
    "\n",
    "    result, header = await make_api_call(url, query, variables=variables)\n",
    "    remaining_request = int(header.get('x-ratelimit-remaining'))\n",
    "    print(f'Remaing API call per min: {remaining_request}')\n",
    "\n",
    "    await queue.put(result)\n",
    "    return result, header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def save_api_to_local(file_path:str, data: dict):\n",
    "    print(f\"Writing to {file_path}\")\n",
    "    with open(file_path, 'w') as fp:\n",
    "        json.dump(data, fp)\n",
    "\n",
    "async def consumer_work(queue: asyncio.Queue, storage_path:Path):\n",
    "\n",
    "    while True:\n",
    "\n",
    "        response_body = await queue.get()\n",
    "        data = response_body.get('data')\n",
    "        current_page = response_body.get('data').get('Page').get('pageInfo').get('currentPage')\n",
    "\n",
    "        file_path = Path(f'page-{current_page}.json')\n",
    "        download_path = storage_path / file_path\n",
    "\n",
    "        await save_api_to_local(file_path=str(download_path), data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def main():\n",
    "MAX_PER_PAGE = 50\n",
    "TOP = 1000\n",
    "MAX_API_PER_MIN = 90\n",
    "total_api_call_count = int(TOP / MAX_PER_PAGE)\n",
    "\n",
    "template_path = Path(r'graphql-template\\get-anime.graphql')\n",
    "with open(str(template_path), 'r') as fp:\n",
    "    template = fp.read()\n",
    "\n",
    "url = 'https://graphql.anilist.co'\n",
    "\n",
    "base_path = Path().cwd().parent\n",
    "storage_path = base_path / Path('raw/anime')\n",
    "\n",
    "queue = asyncio.Queue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_coros = [producer_work(queue, page_num, url, template, MAX_PER_PAGE)\n",
    "    for page_num in range(6, total_api_call_count+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting page 6 at https://graphql.anilist.co\n",
      "Requesting page 7 at https://graphql.anilist.co\n",
      "Requesting page 8 at https://graphql.anilist.co\n",
      "Requesting page 9 at https://graphql.anilist.co\n",
      "Requesting page 10 at https://graphql.anilist.co\n",
      "Requesting page 11 at https://graphql.anilist.co\n",
      "Requesting page 12 at https://graphql.anilist.co\n",
      "Requesting page 13 at https://graphql.anilist.co\n",
      "Requesting page 14 at https://graphql.anilist.co\n",
      "Requesting page 15 at https://graphql.anilist.co\n",
      "Requesting page 16 at https://graphql.anilist.co\n",
      "Requesting page 17 at https://graphql.anilist.co\n",
      "Requesting page 18 at https://graphql.anilist.co\n",
      "Requesting page 19 at https://graphql.anilist.co\n",
      "Requesting page 20 at https://graphql.anilist.co\n"
     ]
    }
   ],
   "source": [
    "# Start work by creating task from initialized coroutines\n",
    "ress = [asyncio.create_task(coro) for coro in producer_coros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaing API call per min: 89\n",
      "Remaing API call per min: 81\n",
      "Remaing API call per min: 88\n",
      "Remaing API call per min: 87\n",
      "Remaing API call per min: 86\n",
      "Remaing API call per min: 85\n",
      "Remaing API call per min: 75\n",
      "Remaing API call per min: 77\n",
      "Remaing API call per min: 83\n",
      "Remaing API call per min: 80\n",
      "Remaing API call per min: 79\n",
      "Remaing API call per min: 76\n",
      "Remaing API call per min: 84\n",
      "Remaing API call per min: 82\n",
      "Remaing API call per min: 78\n"
     ]
    }
   ],
   "source": [
    "consumer_coros = [consumer_work(queue, storage_path) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-11.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-6.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-19.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-14.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-7.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-18.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-8.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-12.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-10.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-9.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-17.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-20.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-16.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-13.json\n",
      "Writing to c:\\Users\\JH\\project\\road-to-data-engineer\\graph-search\\graph-search-data-engineering\\raw\\anime\\page-15.json\n"
     ]
    }
   ],
   "source": [
    "consumer_responses = [asyncio.create_task(coro) for coro in consumer_coros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "await queue.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue.empty()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
